# -*- coding: utf-8 -*-
"""
Created on Tue Feb 25 10:39:21 2020

@author: Manish Chauhan +91-9774083186

"""

import tableauserverclient as TSC
import pandas as pd
import shutil
import os

 
print("-------------------------------------------------------------------------")
print("Importing of modules completed")
print("-------------------------------------------------------------------------")
 

# Variable Declaration & Initialization
# Path of Data event to Tableau Extract Mapping
# File should be Comma separated with .csv
Path_Dataevent_to_Tableau_Mapping='C://Users/admin/Desktop/Event_Extract_map.csv'
 
# Path of Data events - landing i.e. Arrival from ETL
Source_Path_Event='C://Users/admin/Desktop/files'
 
# Path of Data events - archival i.e. Archive post trigger of Tableau extract
Destination_Path='C://Users/admin/Desktop/filesa'

serv='http://laptop-r8gnfcla'
uname='Your Tableau Username'
pwd='Your Tableau Password '
site=''  # If site is Default then leave it blank else pass the site name AS ('https://mytableau.com/MYSITE')

print("-------------------------------------------------------------------------")
print("Variable Initialization Completed")
print("-------------------------------------------------------------------------")

#Capturing the number of events by listing the number of files generated by DB on refresh
list_data_events=os.listdir(Source_Path_Event)
print("-------------------------------------------------------------------------")
print("Number of new data events found: " + str(len(list_data_events)))
print("Data Events Files: " + str(list_data_events))
print("-------------------------------------------------------------------------")

# Identify unique data events
df_dataevents=pd.DataFrame(list_data_events,columns={'FileName'})
#print(df_dataevents)
df_dataevents['EventsName']= df_dataevents['FileName'].apply(lambda x: str(x)[0:str(x).rfind("_")])
#print(df_uniquedataevents)
df_uniquedataevents=pd.DataFrame(df_dataevents['EventsName'].unique(),columns={'EventName'})


print("-------------------------------------------------------------------------")
print("Number of Unique data events found: " + str(len(df_uniquedataevents)))
print("Unique data events: " + str(df_uniquedataevents))
print("-------------------------------------------------------------------------")
  
# Import the Data event to Extract mapping
df_dataeventtoextractmapping=pd.read_csv(Path_Dataevent_to_Tableau_Mapping)
 
#Identify the unique extracts to be refreshed
df_extracts=pd.merge(df_uniquedataevents,df_dataeventtoextractmapping,how='inner',left_on=['EventName'],right_on=['File_name'])

#listuniqueextracts=dfextracts['Extract_Name']+'Project'].unique()
df_temp=(df_extracts.iloc[:,[2]])
print(df_temp)


# Creating a list of datasources which needs to be refreshed 
f_list=[]
for index,row in (df_temp).iterrows():
      f_list.append(df_temp.iloc[index][0])
print(f_list)   
      
'''------------------------------------------------------------------------------------------------------------'''
#creating the Authentication Object:tableau_auth

tableau_auth = TSC.TableauAuth(uname,pwd, site)

# Creating the Server Object:server
server = TSC.Server(serv)

#This will ignore the SSL certificate check(use this only if tableau server has SSL configured)
server.add_http_options({'verify': False}) 

# Setting Server API version i.e latest as of now
server.version = '3.1'

with server.auth.sign_in(tableau_auth):
   print("-------------------------------------------------------------------------")
   print(" Signed In As " + uname)
   print("-------------------------------------------------------------------------")

# Getting list of all data sources on tableau server by ID
   all_datasources, pagination_item = server.datasources.get()
   
#   print("\nThere are {} datasources on site: ".format(pagination_item.total_available))
   datasource_id=([datasource.id for datasource in all_datasources])
   datasource_name=([datasource.name for datasource in all_datasources])
##   print(datasource_id)
##   print(datasource_name)
# Creating dataframe with all the data source name and id's
   df_tableau_datasource=pd.DataFrame(datasource_id,index=datasource_name,columns=['ds_Id'])
# Fetching Id's of datasources listed in F_list[]  
   for i in range(len(f_list)):
       print(f_list[i])
       idw=df_tableau_datasource.loc[f_list[i],['ds_Id']]
       print(idw)
       id_pass=idw[0]     
# Get the data source item to update
       datasource = server.datasources.get_by_id(id_pass)
   
# Call the refresh method with the data source item
       server.datasources.refresh(datasource)
       print("-------------------------------------------------------------------------")
       print("Refresh Started Sucessfully for "+f_list[i])
       print("-------------------------------------------------------------------------")
       
# Move Data event files to Archive Folder
 
for fileitem in list_data_events:
    print(fileitem)
    shutil.move(Source_Path_Event+'/'+fileitem, Destination_Path+'/'+fileitem)
print("-------------------------------------------------------------------------")
print("Data Events Files Moved from Landing to Archive")
print("-------------------------------------------------------------------------")
    
